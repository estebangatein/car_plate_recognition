{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports and utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-10T12:08:49.799846Z",
     "iopub.status.busy": "2025-06-10T12:08:49.799510Z",
     "iopub.status.idle": "2025-06-10T12:08:53.177784Z",
     "shell.execute_reply": "2025-06-10T12:08:53.176724Z",
     "shell.execute_reply.started": "2025-06-10T12:08:49.799822Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "!git clone https://github.com/ultralytics/yolov5.git\n",
    "%cd yolov5\n",
    "!pip install -r requirements.txt --quiet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2025-06-10T12:08:53.180341Z",
     "iopub.status.busy": "2025-06-10T12:08:53.179551Z",
     "iopub.status.idle": "2025-06-10T12:08:54.340034Z",
     "shell.execute_reply": "2025-06-10T12:08:54.339451Z",
     "shell.execute_reply.started": "2025-06-10T12:08:53.180312Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import cv2\n",
    "import os\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from tqdm import tqdm\n",
    "from models.yolo import Model\n",
    "from utils.loss import ComputeLoss\n",
    "import yaml\n",
    "import urllib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-10T12:08:54.341379Z",
     "iopub.status.busy": "2025-06-10T12:08:54.340874Z",
     "iopub.status.idle": "2025-06-10T12:08:54.349152Z",
     "shell.execute_reply": "2025-06-10T12:08:54.348580Z",
     "shell.execute_reply.started": "2025-06-10T12:08:54.341360Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# utils for decoding the labels\n",
    "\n",
    "provinces = [\"皖\", \"沪\", \"津\", \"渝\", \"冀\", \"晋\", \"蒙\", \"辽\", \"吉\", \"黑\", \"苏\", \"浙\", \"京\", \"闽\", \"赣\", \"鲁\", \"豫\", \"鄂\", \"湘\", \"粤\", \"桂\", \"琼\", \"川\", \"贵\", \"云\", \"藏\", \"陕\", \"甘\", \"青\", \"宁\", \"新\", \"警\", \"学\", \"O\"]\n",
    "alphabets = ['A', 'B', 'C', 'D', 'E', 'F', 'G', 'H', 'J', 'K', 'L', 'M', 'N', 'P', 'Q', 'R', 'S', 'T', 'U', 'V', 'W',\n",
    "             'X', 'Y', 'Z', 'O']\n",
    "ads = ['A', 'B', 'C', 'D', 'E', 'F', 'G', 'H', 'J', 'K', 'L', 'M', 'N', 'P', 'Q', 'R', 'S', 'T', 'U', 'V', 'W', 'X',\n",
    "       'Y', 'Z', '0', '1', '2', '3', '4', '5', '6', '7', '8', '9', 'O']\n",
    "\n",
    "# decodes the plate from the file name\n",
    "def decode_plate(label_str):\n",
    "    indices = list(map(int, label_str.split('_')))\n",
    "    province = provinces[indices[0]]\n",
    "    alphabet = alphabets[indices[1]]\n",
    "    ad = ''\n",
    "    for i in range(2, len(indices)):\n",
    "        ad += ads[indices[i]]\n",
    "\n",
    "    return province + alphabet + ad\n",
    "\n",
    "full_charset = provinces[:-1] + alphabets[:-1] + ads[:-1]\n",
    "char_to_idx = {char: idx+1 for idx, char in enumerate(full_charset)}  # leave 0 for CTC blank\n",
    "idx_to_char = {idx: char for char, idx in char_to_idx.items()}\n",
    "\n",
    "def encode_plate(text: str) -> List[int]:\n",
    "    return [char_to_idx[c] for c in text if c in char_to_idx]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-10T12:08:54.351202Z",
     "iopub.status.busy": "2025-06-10T12:08:54.350965Z",
     "iopub.status.idle": "2025-06-10T12:08:54.374764Z",
     "shell.execute_reply": "2025-06-10T12:08:54.374214Z",
     "shell.execute_reply.started": "2025-06-10T12:08:54.351186Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# torch dataset\n",
    "class LicensePlateCCPDDataset(Dataset):\n",
    "    def __init__(self, image_dir, transform=None, img_size=(640, 640)):\n",
    "        self.image_dir = image_dir\n",
    "        self.image_files = [f for f in os.listdir(image_dir) if f.endswith('.jpg')]\n",
    "        self.transform = transform\n",
    "        self.img_size = img_size  # (H, W)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.image_files)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        filename = self.image_files[idx]\n",
    "        path = os.path.join(self.image_dir, filename)\n",
    "\n",
    "        # load image\n",
    "        image = cv2.imread(path)\n",
    "        image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "        # needed to scale the bounding box\n",
    "        original_h, original_w = image.shape[:2]\n",
    "\n",
    "        # bounding box from filename\n",
    "        parts = filename.split('-')\n",
    "        bbox_part = parts[2]\n",
    "        x1y1, x2y2 = bbox_part.split('_')\n",
    "        x1, y1 = map(int, x1y1.split('~'))\n",
    "        x2, y2 = map(int, x2y2.split('~'))\n",
    "\n",
    "        # resize image to 640x640 using + intensity normalization\n",
    "        resized_image = cv2.resize(image, self.img_size[::-1])\n",
    "        image_tensor = torch.tensor(resized_image, dtype=torch.float32).permute(2, 0, 1) / 255.0\n",
    "\n",
    "        # adjust bbox to resized scale\n",
    "        scale_x = self.img_size[1] / original_w\n",
    "        scale_y = self.img_size[0] / original_h\n",
    "\n",
    "        x1_resized = x1 * scale_x / self.img_size[1]\n",
    "        x2_resized = x2 * scale_x / self.img_size[1]\n",
    "        y1_resized = y1 * scale_y / self.img_size[0]\n",
    "        y2_resized = y2 * scale_y / self.img_size[0]\n",
    "\n",
    "        bbox = torch.tensor([x1_resized, y1_resized, x2_resized, y2_resized], dtype=torch.float32)\n",
    "\n",
    "        # plate text\n",
    "        plate_raw = parts[4]\n",
    "        plate_text = decode_plate(plate_raw)\n",
    "\n",
    "        return image_tensor, plate_text, bbox"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-10T12:08:54.375508Z",
     "iopub.status.busy": "2025-06-10T12:08:54.375324Z",
     "iopub.status.idle": "2025-06-10T12:08:54.404087Z",
     "shell.execute_reply": "2025-06-10T12:08:54.403557Z",
     "shell.execute_reply.started": "2025-06-10T12:08:54.375493Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# creates the dataset and dataloader\n",
    "dataset = LicensePlateCCPDDataset(\"/kaggle/input/ccpd-weather/ccpd_weather\")\n",
    "loader = DataLoader(dataset, batch_size=8, shuffle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Detection (YOLO)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-10T12:08:54.404934Z",
     "iopub.status.busy": "2025-06-10T12:08:54.404735Z",
     "iopub.status.idle": "2025-06-10T12:08:54.904003Z",
     "shell.execute_reply": "2025-06-10T12:08:54.903457Z",
     "shell.execute_reply.started": "2025-06-10T12:08:54.404920Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# utils\n",
    "num_classes = 1  # just detecting plates (needed as YOLO is also a classifier)\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model = Model(cfg='models/yolov5s.yaml', ch=3, nc=num_classes).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-10T12:08:54.904867Z",
     "iopub.status.busy": "2025-06-10T12:08:54.904658Z",
     "iopub.status.idle": "2025-06-10T12:08:55.348088Z",
     "shell.execute_reply": "2025-06-10T12:08:55.347172Z",
     "shell.execute_reply.started": "2025-06-10T12:08:54.904849Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# downloads pretrained weights\n",
    "url = 'https://github.com/ultralytics/yolov5/releases/download/v6.0/yolov5s.pt'\n",
    "output_path = 'yolov5s.pt'\n",
    "\n",
    "urllib.request.urlretrieve(url, output_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-10T12:08:55.349150Z",
     "iopub.status.busy": "2025-06-10T12:08:55.348934Z",
     "iopub.status.idle": "2025-06-10T12:08:55.458891Z",
     "shell.execute_reply": "2025-06-10T12:08:55.458304Z",
     "shell.execute_reply.started": "2025-06-10T12:08:55.349132Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# loads the weights to the model structure\n",
    "weights = torch.load('yolov5s.pt', map_location=device)['model'].float().state_dict()\n",
    "model_dict = model.state_dict()\n",
    "\n",
    "# skip last layer (avoid classifier)\n",
    "filtered_weights = {k: v for k, v in weights.items() if not k.startswith('model.24.')}\n",
    "\n",
    "# loads updated weights\n",
    "model_dict.update(filtered_weights)\n",
    "model.load_state_dict(model_dict, strict=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-10T12:08:55.459992Z",
     "iopub.status.busy": "2025-06-10T12:08:55.459685Z",
     "iopub.status.idle": "2025-06-10T12:08:55.466070Z",
     "shell.execute_reply": "2025-06-10T12:08:55.465329Z",
     "shell.execute_reply.started": "2025-06-10T12:08:55.459966Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# bbox conversion function to YOLO format\n",
    "def convert_to_yolo_format_normalized(boxes, image_index, default_label=0):\n",
    "    \n",
    "    if boxes.ndim == 1:\n",
    "        boxes = boxes.unsqueeze(0) \n",
    "\n",
    "    if boxes.numel() == 0:\n",
    "        return torch.empty((0, 6))\n",
    "    \n",
    "    x1 = boxes[:, 0]\n",
    "    y1 = boxes[:, 1]\n",
    "    x2 = boxes[:, 2]\n",
    "    y2 = boxes[:, 3]\n",
    "\n",
    "    x_center = (x1 + x2) / 2\n",
    "    y_center = (y1 + y2) / 2\n",
    "    width = x2 - x1\n",
    "    height = y2 - y1\n",
    "\n",
    "    image_idx = torch.full((boxes.size(0),), fill_value=image_index, dtype=torch.float32)\n",
    "    labels = torch.full((boxes.size(0),), fill_value=default_label, dtype=torch.float32)\n",
    "\n",
    "    # same format as YOLO predictions\n",
    "    target = torch.stack([image_idx, labels, x_center, y_center, width, height], dim=1)\n",
    "    return target\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-10T12:17:46.089444Z",
     "iopub.status.busy": "2025-06-10T12:17:46.088658Z",
     "iopub.status.idle": "2025-06-10T12:17:46.097233Z",
     "shell.execute_reply": "2025-06-10T12:17:46.096484Z",
     "shell.execute_reply.started": "2025-06-10T12:17:46.089416Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# loads the YOLO loss function (based on IoU)\n",
    "with open('data/hyps/hyp.scratch-low.yaml') as f:\n",
    "    hyp = yaml.safe_load(f)\n",
    "\n",
    "model.hyp = hyp\n",
    "compute_loss = ComputeLoss(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-10T12:19:56.918047Z",
     "iopub.status.busy": "2025-06-10T12:19:56.917768Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# utils\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=1e-3)\n",
    "model = model.to(device)\n",
    "\n",
    "# training loop\n",
    "for epoch in range(15):\n",
    "    model.train()\n",
    "    running_loss = 0\n",
    "\n",
    "    for i, (imgs, _, annotations) in enumerate(tqdm(loader)):\n",
    "        imgs = imgs.to(device)\n",
    "\n",
    "        # need to convert the labels with the function\n",
    "        targets = []\n",
    "        for j in range(len(imgs)):\n",
    "            boxes = annotations[j]\n",
    "            yolo_target = convert_to_yolo_format_normalized(boxes, image_index=j)\n",
    "            targets.append(yolo_target)\n",
    "\n",
    "        if len(targets) == 0: # just in case\n",
    "            continue\n",
    "\n",
    "        targets = torch.cat(targets, dim=0).to(device)\n",
    "\n",
    "        outputs = model(imgs)  # only returning outputs, but still modifying weights (through loss)\n",
    "        loss, _ = compute_loss(outputs, targets) # using personalized loss\n",
    "\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        running_loss += loss.item()\n",
    "\n",
    "    print(f\"Epoch {epoch} - Loss: {running_loss / len(loader)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# saves the model\n",
    "torch.save(model.state_dict(), \"my_yolov5.pth\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# check uploading weights works\n",
    "model = Model('models/yolov5s.yaml', ch=3, nc=1).to(device)\n",
    "\n",
    "state_dict = torch.load(\"my_yolov5.pth\", map_location=device)\n",
    "model.load_state_dict(state_dict) \n",
    "model.eval() "
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "nvidiaTeslaT4",
   "dataSources": [
    {
     "datasetId": 7554659,
     "sourceId": 12008457,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 31041,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
