{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports and utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2025-06-10T16:11:23.847728Z",
     "iopub.status.busy": "2025-06-10T16:11:23.847400Z",
     "iopub.status.idle": "2025-06-10T16:11:23.852808Z",
     "shell.execute_reply": "2025-06-10T16:11:23.851901Z",
     "shell.execute_reply.started": "2025-06-10T16:11:23.847703Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import cv2\n",
    "import os\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torch.nn as nn\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-10T16:11:23.854482Z",
     "iopub.status.busy": "2025-06-10T16:11:23.853984Z",
     "iopub.status.idle": "2025-06-10T16:11:23.871970Z",
     "shell.execute_reply": "2025-06-10T16:11:23.871238Z",
     "shell.execute_reply.started": "2025-06-10T16:11:23.854458Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# utils for decoding the labels\n",
    "\n",
    "provinces = [\"皖\", \"沪\", \"津\", \"渝\", \"冀\", \"晋\", \"蒙\", \"辽\", \"吉\", \"黑\", \"苏\", \"浙\", \"京\", \"闽\", \"赣\", \"鲁\", \"豫\", \"鄂\", \"湘\", \"粤\", \"桂\", \"琼\", \"川\", \"贵\", \"云\", \"藏\", \"陕\", \"甘\", \"青\", \"宁\", \"新\", \"警\", \"学\", \"O\"]\n",
    "alphabets = ['A', 'B', 'C', 'D', 'E', 'F', 'G', 'H', 'J', 'K', 'L', 'M', 'N', 'P', 'Q', 'R', 'S', 'T', 'U', 'V', 'W',\n",
    "             'X', 'Y', 'Z', 'O']\n",
    "ads = ['A', 'B', 'C', 'D', 'E', 'F', 'G', 'H', 'J', 'K', 'L', 'M', 'N', 'P', 'Q', 'R', 'S', 'T', 'U', 'V', 'W', 'X',\n",
    "       'Y', 'Z', '0', '1', '2', '3', '4', '5', '6', '7', '8', '9', 'O']\n",
    "\n",
    "# decodes the plate from the file name\n",
    "def decode_plate(label_str):\n",
    "    indices = list(map(int, label_str.split('_')))\n",
    "    province = provinces[indices[0]]\n",
    "    alphabet = alphabets[indices[1]]\n",
    "    ad = ''\n",
    "    for i in range(2, len(indices)):\n",
    "        ad += ads[indices[i]]\n",
    "\n",
    "    return province + alphabet + ad\n",
    "\n",
    "full_charset = provinces[:-1] + alphabets[:-1] + ads[:-1]\n",
    "char_to_idx = {char: idx+1 for idx, char in enumerate(full_charset)}  # leave 0 for CTC blank\n",
    "idx_to_char = {idx: char for char, idx in char_to_idx.items()}\n",
    "\n",
    "# encodes plate for the model\n",
    "def encode_plate(text: str) -> List[int]:\n",
    "    return [char_to_idx[c] for c in text if c in char_to_idx]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-10T16:11:23.873702Z",
     "iopub.status.busy": "2025-06-10T16:11:23.873115Z",
     "iopub.status.idle": "2025-06-10T16:11:23.891532Z",
     "shell.execute_reply": "2025-06-10T16:11:23.890977Z",
     "shell.execute_reply.started": "2025-06-10T16:11:23.873677Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# torch dataset\n",
    "class LicensePlateCCPDDataset(Dataset):\n",
    "    def __init__(self, image_dir):\n",
    "        self.image_dir = image_dir\n",
    "        self.image_files = [f for f in os.listdir(image_dir) if f.endswith('.jpg')]\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.image_files)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        filename = self.image_files[idx]\n",
    "        path = os.path.join(self.image_dir, filename)\n",
    "    \n",
    "        # load image\n",
    "        image = cv2.imread(path)\n",
    "        image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "    \n",
    "        # bbox from filename\n",
    "        parts = filename.split('-')\n",
    "        bbox_part = parts[2]\n",
    "        x1y1, x2y2 = bbox_part.split('_')\n",
    "        x1, y1 = map(int, x1y1.split('~'))\n",
    "        x2, y2 = map(int, x2y2.split('~'))\n",
    "    \n",
    "        # crop given the plate bbox\n",
    "        h, w = image.shape[:2]\n",
    "        x1, x2 = max(0, x1), min(w, x2)\n",
    "        y1, y2 = max(0, y1), min(h, y2)\n",
    "        cropped = image[y1:y2, x1:x2]\n",
    "    \n",
    "        # resize as the paper\n",
    "        cropped = cv2.resize(cropped, (144, 48))\n",
    "        image_tensor = torch.tensor(cropped, dtype=torch.float32).permute(2, 0, 1) / 255.0\n",
    "\n",
    "        # plate text\n",
    "        plate_raw = parts[4]\n",
    "        plate_text = decode_plate(plate_raw)\n",
    "    \n",
    "        return image_tensor, plate_text\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-10T16:11:23.892699Z",
     "iopub.status.busy": "2025-06-10T16:11:23.892441Z",
     "iopub.status.idle": "2025-06-10T16:11:23.917461Z",
     "shell.execute_reply": "2025-06-10T16:11:23.916756Z",
     "shell.execute_reply.started": "2025-06-10T16:11:23.892677Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# creates the dataset and dataloader\n",
    "dataset = LicensePlateCCPDDataset(\"/kaggle/input/ccpd-weather/ccpd_weather\")\n",
    "loader = DataLoader(dataset, batch_size=8, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-10T16:11:23.919008Z",
     "iopub.status.busy": "2025-06-10T16:11:23.918741Z",
     "iopub.status.idle": "2025-06-10T16:11:23.935291Z",
     "shell.execute_reply": "2025-06-10T16:11:23.934762Z",
     "shell.execute_reply.started": "2025-06-10T16:11:23.918986Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# image downsampling (better than pooling)\n",
    "class Focus(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels):\n",
    "        super().__init__()\n",
    "        self.conv = nn.Conv2d(in_channels * 4, out_channels, 3, 1, 1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.conv(torch.cat([\n",
    "            x[..., ::2, ::2],\n",
    "            x[..., ::2, 1::2],\n",
    "            x[..., 1::2, ::2],\n",
    "            x[..., 1::2, 1::2]\n",
    "        ], dim=1))\n",
    "\n",
    "# convolution sequence block\n",
    "class ConvBlock(nn.Module):\n",
    "    def __init__(self, in_ch, out_ch, k=3, s=1, p=1):\n",
    "        super().__init__()\n",
    "        self.conv = nn.Conv2d(in_ch, out_ch, kernel_size=k, stride=s, padding=p)\n",
    "        self.bn = nn.BatchNorm2d(out_ch)  \n",
    "        self.act = nn.LeakyReLU(0.1, inplace=False)\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.act(self.bn(self.conv(x)))\n",
    "\n",
    "# residual blocks\n",
    "class ResBlock(nn.Module):\n",
    "    def __init__(self, ch):\n",
    "        super().__init__()\n",
    "        self.block = nn.Sequential(\n",
    "            ConvBlock(ch, ch),\n",
    "            ConvBlock(ch, ch)\n",
    "        )\n",
    "        self.bn = nn.BatchNorm2d(ch) \n",
    "\n",
    "    def forward(self, x):\n",
    "        out = self.block(x)\n",
    "        return self.bn(x + out)\n",
    "\n",
    "\n",
    "# Image Global Feature Extractor block (combines the previous blocks)\n",
    "class IGFE(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.focus = Focus(3, 64)\n",
    "        self.down1 = ConvBlock(64, 128, s=2)\n",
    "        self.down2 = ConvBlock(128, 256, s=2)\n",
    "        self.res = nn.Sequential(\n",
    "            ResBlock(256),\n",
    "            ResBlock(256),\n",
    "            ResBlock(256),\n",
    "            ResBlock(256)\n",
    "        )\n",
    "        self.conv_out = nn.Conv2d(256, 512, 1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.focus(x)\n",
    "        x = self.down1(x)\n",
    "        x = self.down2(x)\n",
    "        x = self.res(x)\n",
    "        x = torch.clamp(x, -10, 10)  # safety clamp\n",
    "        x = self.conv_out(x)\n",
    "        return x\n",
    "\n",
    "# transformer encoding from image\n",
    "class TransformerEncoder(nn.Module):\n",
    "    def __init__(self, d_model=512, nhead=8, num_layers=3):\n",
    "        super().__init__()\n",
    "        self.pos_embed = nn.Parameter(torch.randn(1, 108, d_model)) \n",
    "        encoder_layer = nn.TransformerEncoderLayer(d_model, nhead, dim_feedforward=2048)\n",
    "        self.encoder = nn.TransformerEncoder(encoder_layer, num_layers)\n",
    "        self.dropout = nn.Dropout(p=0.1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        B, C, H, W = x.shape\n",
    "        x = x.view(B, C, -1).permute(0, 2, 1)  \n",
    "        x = self.dropout(x + self.pos_embed)\n",
    "        x = self.encoder(x)\n",
    "        return x\n",
    "\n",
    "\n",
    "\n",
    "# prediction block (decodes the text)\n",
    "class ParallelDecoder(nn.Module):\n",
    "    def __init__(self, d_model=512, num_classes=92):\n",
    "        super().__init__()\n",
    "        self.head = nn.Linear(d_model, num_classes)\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.head(x)\n",
    "\n",
    "# full model (Parallel Deep-Learning License Plate Recognition)\n",
    "class PDLPRModel(nn.Module):\n",
    "    def __init__(self, num_classes=92):\n",
    "        super().__init__()\n",
    "        self.igfe = IGFE()\n",
    "        self.encoder = TransformerEncoder()\n",
    "        self.decoder = ParallelDecoder(num_classes=num_classes)\n",
    "\n",
    "        self._init_weights()\n",
    "\n",
    "\n",
    "    def _init_weights(self): # needed because of unstable training\n",
    "        for m in self.modules():\n",
    "            if isinstance(m, nn.Conv2d):\n",
    "                nn.init.kaiming_normal_(m.weight, mode='fan_out', nonlinearity='relu')\n",
    "                if m.bias is not None:\n",
    "                    nn.init.constant_(m.bias, 0)\n",
    "            elif isinstance(m, nn.BatchNorm2d):\n",
    "                nn.init.constant_(m.weight, 1)\n",
    "                nn.init.constant_(m.bias, 0)\n",
    "            elif isinstance(m, nn.Linear):\n",
    "                nn.init.xavier_uniform_(m.weight)\n",
    "                nn.init.constant_(m.bias, 0)\n",
    "    \n",
    "\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.igfe(x)\n",
    "        x = self.encoder(x)\n",
    "        x = self.decoder(x)\n",
    "\n",
    "        return x\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-10T16:11:23.982633Z",
     "iopub.status.busy": "2025-06-10T16:11:23.981947Z",
     "iopub.status.idle": "2025-06-10T16:11:24.166525Z",
     "shell.execute_reply": "2025-06-10T16:11:24.165945Z",
     "shell.execute_reply.started": "2025-06-10T16:11:23.982610Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# model initialization and utils\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "model = PDLPRModel(num_classes=92).to(device)\n",
    "\n",
    "ctc_loss = nn.CTCLoss(blank=0, zero_infinity=True, reduction='sum') # reduction defined for stability\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=1e-3)\n",
    "scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=20, gamma=0.9) # as in paper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-10T16:12:22.251021Z",
     "iopub.status.busy": "2025-06-10T16:12:22.250208Z",
     "iopub.status.idle": "2025-06-10T16:12:26.041755Z",
     "shell.execute_reply": "2025-06-10T16:12:26.040583Z",
     "shell.execute_reply.started": "2025-06-10T16:12:22.250991Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# training loop\n",
    "for epoch in range(50):\n",
    "    model.train()\n",
    "    total_loss = 0\n",
    "\n",
    "    for imgs, texts in tqdm(loader):\n",
    "        imgs = imgs.to(device)\n",
    "\n",
    "        # encoding targets\n",
    "        encoded_targets = [torch.tensor(encode_plate(t), dtype=torch.long) for t in texts]\n",
    "        target_lengths = torch.tensor([len(seq) for seq in encoded_targets], dtype=torch.long)\n",
    "        targets = torch.cat(encoded_targets)\n",
    "\n",
    "        # all have same input length (108 from encoder block)\n",
    "        input_lengths = torch.full(size=(imgs.size(0),), fill_value=108, dtype=torch.long)\n",
    "\n",
    "        # forward\n",
    "        logits = model(imgs)\n",
    "        log_probs = logits.log_softmax(2).permute(1, 0, 2)\n",
    "\n",
    "        # loss = simple_ctc_loss(log_probs,targets,input_lengths,target_lengths,blank=0)\n",
    "        # uses CTC from torch\n",
    "        loss = ctc_loss(\n",
    "            log_probs,\n",
    "            targets,\n",
    "            input_lengths,\n",
    "            target_lengths\n",
    "        )\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()  \n",
    "        torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=1.0)\n",
    "        optimizer.step()\n",
    "\n",
    "        total_loss += loss.item()\n",
    "\n",
    "    scheduler.step()\n",
    "\n",
    "    print(f\"Epoch [{epoch}/50] - Loss: {total_loss / len(loader):.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# saves the weights\n",
    "torch.save(model.state_dict(), \"pdlpr_model_weights.pth\")"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "nvidiaTeslaT4",
   "dataSources": [
    {
     "datasetId": 7554659,
     "sourceId": 12008457,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 31040,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
