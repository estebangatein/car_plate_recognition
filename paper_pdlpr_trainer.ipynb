{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2025-06-13T18:31:22.052160Z",
     "iopub.status.busy": "2025-06-13T18:31:22.051820Z",
     "iopub.status.idle": "2025-06-13T18:31:22.057674Z",
     "shell.execute_reply": "2025-06-13T18:31:22.056994Z",
     "shell.execute_reply.started": "2025-06-13T18:31:22.052137Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import cv2\n",
    "import os\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.nn.utils import clip_grad_norm_\n",
    "import torch.nn as nn\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-13T18:31:22.061884Z",
     "iopub.status.busy": "2025-06-13T18:31:22.061581Z",
     "iopub.status.idle": "2025-06-13T18:31:22.085860Z",
     "shell.execute_reply": "2025-06-13T18:31:22.084941Z",
     "shell.execute_reply.started": "2025-06-13T18:31:22.061862Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# utils for decoding the labels\n",
    "\n",
    "provinces = [\"皖\", \"沪\", \"津\", \"渝\", \"冀\", \"晋\", \"蒙\", \"辽\", \"吉\", \"黑\", \"苏\", \"浙\", \"京\", \"闽\", \"赣\", \"鲁\", \"豫\", \"鄂\", \"湘\", \"粤\", \"桂\", \"琼\", \"川\", \"贵\", \"云\", \"藏\", \"陕\", \"甘\", \"青\", \"宁\", \"新\", \"警\", \"学\", \"O\"]\n",
    "alphabets = ['A', 'B', 'C', 'D', 'E', 'F', 'G', 'H', 'J', 'K', 'L', 'M', 'N', 'P', 'Q', 'R', 'S', 'T', 'U', 'V', 'W',\n",
    "             'X', 'Y', 'Z', 'O']\n",
    "ads = ['A', 'B', 'C', 'D', 'E', 'F', 'G', 'H', 'J', 'K', 'L', 'M', 'N', 'P', 'Q', 'R', 'S', 'T', 'U', 'V', 'W', 'X',\n",
    "       'Y', 'Z', '0', '1', '2', '3', '4', '5', '6', '7', '8', '9', 'O']\n",
    "\n",
    "# decodes the plate from the file name\n",
    "def decode_plate(label_str):\n",
    "    indices = list(map(int, label_str.split('_')))\n",
    "    province = provinces[indices[0]]\n",
    "    alphabet = alphabets[indices[1]]\n",
    "    ad = ''\n",
    "    for i in range(2, len(indices)):\n",
    "        ad += ads[indices[i]]\n",
    "\n",
    "    return province + alphabet + ad\n",
    "\n",
    "full_charset = provinces[:-1] + alphabets[:-1] + ads[:-1]\n",
    "char_to_idx = {char: idx+1 for idx, char in enumerate(full_charset)}  # leave 0 for CTC blank\n",
    "idx_to_char = {idx: char for char, idx in char_to_idx.items()}\n",
    "\n",
    "# encodes plate for the model\n",
    "def encode_plate(text: str):\n",
    "    return [char_to_idx[c] for c in text if c in char_to_idx]\n",
    "\n",
    "# decodes plate from the model\n",
    "def decode_plate_model(indices):\n",
    "    return ''.join([idx_to_char.get(idx, '') for idx in indices if idx != 0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-13T18:31:22.087635Z",
     "iopub.status.busy": "2025-06-13T18:31:22.087333Z",
     "iopub.status.idle": "2025-06-13T18:31:22.104469Z",
     "shell.execute_reply": "2025-06-13T18:31:22.103695Z",
     "shell.execute_reply.started": "2025-06-13T18:31:22.087605Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# torch dataset\n",
    "class LicensePlateCCPDDataset(Dataset):\n",
    "    def __init__(self, image_dir):\n",
    "        self.image_dir = image_dir\n",
    "        self.image_files = [f for f in os.listdir(image_dir) if f.endswith('.jpg')]\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.image_files)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        filename = self.image_files[idx]\n",
    "        path = os.path.join(self.image_dir, filename)\n",
    "    \n",
    "        # load image\n",
    "        image = cv2.imread(path)\n",
    "        image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "    \n",
    "        # bbox from filename\n",
    "        parts = filename.split('-')\n",
    "        bbox_part = parts[2]\n",
    "        x1y1, x2y2 = bbox_part.split('_')\n",
    "        x1, y1 = map(int, x1y1.split('~'))\n",
    "        x2, y2 = map(int, x2y2.split('~'))\n",
    "    \n",
    "        # crop given the plate bbox\n",
    "        h, w = image.shape[:2]\n",
    "        x1, x2 = max(0, x1), min(w, x2)\n",
    "        y1, y2 = max(0, y1), min(h, y2)\n",
    "        cropped = image[y1:y2, x1:x2]\n",
    "    \n",
    "        # resize as the paper\n",
    "        cropped = cv2.resize(cropped, (144, 48))\n",
    "        image_tensor = (torch.tensor(cropped, dtype=torch.float32).permute(2, 0, 1) / 255.0 - 0.5) / 0.5 # between -1 and 1\n",
    "\n",
    "        # plate text\n",
    "        plate_raw = parts[4]\n",
    "        plate_text = decode_plate(plate_raw)\n",
    "    \n",
    "        return image_tensor, plate_text\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-13T18:31:22.105689Z",
     "iopub.status.busy": "2025-06-13T18:31:22.105314Z",
     "iopub.status.idle": "2025-06-13T18:31:22.132849Z",
     "shell.execute_reply": "2025-06-13T18:31:22.131848Z",
     "shell.execute_reply.started": "2025-06-13T18:31:22.105660Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# creates the dataset and dataloader\n",
    "dataset = LicensePlateCCPDDataset(\"/kaggle/input/ccpd-weather/ccpd_weather\")\n",
    "loader = DataLoader(dataset, batch_size=16, shuffle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-13T18:31:22.161399Z",
     "iopub.status.busy": "2025-06-13T18:31:22.160586Z",
     "iopub.status.idle": "2025-06-13T18:31:22.186465Z",
     "shell.execute_reply": "2025-06-13T18:31:22.185718Z",
     "shell.execute_reply.started": "2025-06-13T18:31:22.161369Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# focus block\n",
    "class Focus(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels):\n",
    "        super().__init__()\n",
    "        self.conv = nn.Conv2d(in_channels * 4, out_channels, 3, 1, 1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.conv(torch.cat([\n",
    "            x[..., ::2, ::2],\n",
    "            x[..., ::2, 1::2],\n",
    "            x[..., 1::2, ::2],\n",
    "            x[..., 1::2, 1::2]\n",
    "        ], dim=1))\n",
    "\n",
    "\n",
    "# convolutional block\n",
    "class ConvBlock(nn.Module):\n",
    "    def __init__(self, in_ch, out_ch, k=3, s=1, p=1):\n",
    "        super().__init__()\n",
    "        self.conv = nn.Conv2d(in_ch, out_ch, kernel_size=k, stride=s, padding=p)\n",
    "        self.bn = nn.BatchNorm2d(out_ch)\n",
    "        self.act = nn.LeakyReLU(0.1, inplace=True)\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.act(self.bn(self.conv(x)))\n",
    "\n",
    "\n",
    "# residual block\n",
    "class ResBlock(nn.Module):\n",
    "    def __init__(self, ch):\n",
    "        super().__init__()\n",
    "        self.block = nn.Sequential(\n",
    "            ConvBlock(ch, ch),\n",
    "            ConvBlock(ch, ch)\n",
    "        )\n",
    "        self.bn = nn.BatchNorm2d(ch)\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.bn(x + self.block(x))\n",
    "\n",
    "\n",
    "# IGFE\n",
    "class IGFE(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.focus = Focus(3, 64)\n",
    "        self.down1 = ConvBlock(64, 128, s=2)\n",
    "        self.res1 = nn.Sequential(ResBlock(128), ResBlock(128))\n",
    "        self.down2 = ConvBlock(128, 256, s=2)\n",
    "        self.res2 = nn.Sequential(ResBlock(256), ResBlock(256))\n",
    "        self.conv_out = nn.Conv2d(256, 512, kernel_size=1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.focus(x)\n",
    "        x = self.down1(x)\n",
    "        x = self.res1(x)\n",
    "        x = self.down2(x)\n",
    "        x = self.res2(x)\n",
    "        x = torch.clamp(x, -10, 10)\n",
    "        return self.conv_out(x)  # (B, 512, 6, 18)\n",
    "\n",
    "\n",
    "# encoder unit\n",
    "class EncoderUnit(nn.Module):\n",
    "    def __init__(self, d_model=512, nhead=8):\n",
    "        super().__init__()\n",
    "        self.cnn1 = nn.Conv1d(d_model, 1024, kernel_size=1)\n",
    "        self.mha = nn.MultiheadAttention(embed_dim=1024, num_heads=nhead, batch_first=True)\n",
    "        self.cnn2 = nn.Conv1d(1024, d_model, kernel_size=1)\n",
    "        self.norm = nn.LayerNorm(d_model)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x_cnn = x.transpose(1, 2)              \n",
    "        x_mha_in = F.relu(self.cnn1(x_cnn)).transpose(1, 2)\n",
    "        attn_out, _ = self.mha(x_mha_in, x_mha_in, x_mha_in) \n",
    "        x_proj = self.cnn2(attn_out.transpose(1, 2)).transpose(1, 2)\n",
    "        return self.norm(x + x_proj)\n",
    "\n",
    "\n",
    "# full encoder\n",
    "class PDLPR_Encoder(nn.Module):\n",
    "    def __init__(self, d_model=512, nhead=8, num_layers=3):\n",
    "        super().__init__()\n",
    "        self.pos_embed = nn.Parameter(torch.randn(1, 108, d_model))\n",
    "        self.dropout = nn.Dropout(p=0.1)\n",
    "        self.layers = nn.Sequential(*[\n",
    "            EncoderUnit(d_model=d_model, nhead=nhead) for _ in range(num_layers)\n",
    "        ])\n",
    "\n",
    "    def forward(self, x):\n",
    "        B, C, H, W = x.shape\n",
    "        x = x.view(B, C, -1).permute(0, 2, 1)  # (B, 108, 512)\n",
    "        x = self.dropout(x + self.pos_embed[:, :x.size(1), :])\n",
    "        return self.layers(x)  # (B, 108, 512)\n",
    "\n",
    "\n",
    "# FFN block (non-linear transformation)\n",
    "class FeedForward(nn.Module):\n",
    "    def __init__(self, d_model=512, hidden_dim=2048):\n",
    "        super().__init__()\n",
    "        self.net = nn.Sequential(\n",
    "            nn.Linear(d_model, hidden_dim),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(hidden_dim, d_model)\n",
    "        )\n",
    "        self.norm = nn.LayerNorm(d_model)\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.norm(x + self.net(x))\n",
    "\n",
    "\n",
    "# decoder unit\n",
    "class DecoderUnit(nn.Module):\n",
    "    def __init__(self, d_model=512, nhead=8):\n",
    "        super().__init__()\n",
    "        self.masked_mha = nn.MultiheadAttention(d_model, nhead, batch_first=True)\n",
    "        self.norm1 = nn.LayerNorm(d_model)\n",
    "\n",
    "        self.encoder_proj = nn.Sequential(\n",
    "            nn.Conv1d(d_model, d_model, kernel_size=1),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv1d(d_model, d_model, kernel_size=1)\n",
    "        )\n",
    "\n",
    "        self.cross_mha = nn.MultiheadAttention(d_model, nhead, batch_first=True)\n",
    "        self.norm2 = nn.LayerNorm(d_model)\n",
    "        self.ffn = FeedForward(d_model)\n",
    "\n",
    "    def forward(self, tgt, memory, tgt_mask=None):\n",
    "        mha_out1, _ = self.masked_mha(tgt, tgt, tgt, attn_mask=tgt_mask)\n",
    "        x = self.norm1(tgt + mha_out1)\n",
    "\n",
    "        mem_proj = memory.transpose(1, 2)\n",
    "        mem_proj = self.encoder_proj(mem_proj).transpose(1, 2)\n",
    "\n",
    "        mha_out2, _ = self.cross_mha(x, mem_proj, mem_proj)\n",
    "        x = self.norm2(x + mha_out2)\n",
    "\n",
    "        return self.ffn(x)\n",
    "\n",
    "\n",
    "# full parallel decoder\n",
    "class ParallelDecoder(nn.Module):\n",
    "    def __init__(self, d_model=512, num_classes=92, nhead=8, num_layers=3, max_seq_len=18):\n",
    "        super().__init__()\n",
    "        self.pos_embed = nn.Parameter(torch.randn(1, max_seq_len, d_model))\n",
    "        self.dropout = nn.Dropout(0.1)\n",
    "\n",
    "        self.decoder_layers = nn.ModuleList([\n",
    "            DecoderUnit(d_model, nhead) for _ in range(num_layers)\n",
    "        ])\n",
    "\n",
    "        self.out_proj = nn.Linear(d_model, num_classes)\n",
    "\n",
    "    def forward(self, encoder_out):\n",
    "        B = encoder_out.size(0)\n",
    "        T = 18\n",
    "        device = encoder_out.device\n",
    "\n",
    "        tgt = torch.zeros(B, T, encoder_out.size(2), device=device) + self.pos_embed[:, :T, :]\n",
    "        tgt = self.dropout(tgt)\n",
    "\n",
    "        mask = torch.triu(torch.ones(T, T, device=device) * float('-inf'), diagonal=1)\n",
    "\n",
    "        for layer in self.decoder_layers:\n",
    "            tgt = layer(tgt, encoder_out, tgt_mask=mask)\n",
    "\n",
    "        return self.out_proj(tgt)  # (B, T, num_classes)\n",
    "\n",
    "\n",
    "# final PDLPRModel\n",
    "class PDLPRModel(nn.Module):\n",
    "    def __init__(self, num_classes=92):\n",
    "        super().__init__()\n",
    "        self.igfe = IGFE()\n",
    "        self.encoder = PDLPR_Encoder()\n",
    "        self.decoder = ParallelDecoder(num_classes=num_classes)\n",
    "\n",
    "        self._init_weights()\n",
    "\n",
    "    def _init_weights(self):\n",
    "        for m in self.modules():\n",
    "            if isinstance(m, nn.Conv2d) or isinstance(m, nn.Conv1d):\n",
    "                nn.init.kaiming_normal_(m.weight, mode='fan_out', nonlinearity='relu')\n",
    "                if m.bias is not None:\n",
    "                    nn.init.constant_(m.bias, 0)\n",
    "            elif isinstance(m, (nn.BatchNorm2d, nn.LayerNorm)):\n",
    "                nn.init.constant_(m.weight, 1)\n",
    "                nn.init.constant_(m.bias, 0)\n",
    "            elif isinstance(m, nn.Linear):\n",
    "                nn.init.xavier_uniform_(m.weight)\n",
    "                nn.init.constant_(m.bias, 0)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.igfe(x)           # (B, 512, 6, 18)\n",
    "        x = self.encoder(x)        # (B, 108, 512)\n",
    "        x = self.decoder(x)        # (B, 18, num_classes)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-13T18:31:22.187981Z",
     "iopub.status.busy": "2025-06-13T18:31:22.187498Z",
     "iopub.status.idle": "2025-06-13T18:31:22.706471Z",
     "shell.execute_reply": "2025-06-13T18:31:22.705827Z",
     "shell.execute_reply.started": "2025-06-13T18:31:22.187948Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# model initialization and utils\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "model = PDLPRModel(num_classes=92).to(device)\n",
    "\n",
    "ctc_loss = nn.CTCLoss(blank=0, zero_infinity=True) # reduction defined for stability\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=1e-2)\n",
    "scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=20, gamma=0.9) # as in paper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-13T18:31:48.397292Z",
     "iopub.status.busy": "2025-06-13T18:31:48.396968Z",
     "iopub.status.idle": "2025-06-13T18:32:00.649149Z",
     "shell.execute_reply": "2025-06-13T18:32:00.648191Z",
     "shell.execute_reply.started": "2025-06-13T18:31:48.397270Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  7%|▋         | 41/625 [00:12<02:54,  3.35it/s]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_35/537517630.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     14\u001b[0m     \u001b[0mtotal_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 16\u001b[0;31m     \u001b[0;32mfor\u001b[0m \u001b[0mimgs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtexts\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtqdm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     17\u001b[0m         \u001b[0mimgs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mimgs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/tqdm/std.py\u001b[0m in \u001b[0;36m__iter__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1179\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1180\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1181\u001b[0;31m             \u001b[0;32mfor\u001b[0m \u001b[0mobj\u001b[0m \u001b[0;32min\u001b[0m \u001b[0miterable\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1182\u001b[0m                 \u001b[0;32myield\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1183\u001b[0m                 \u001b[0;31m# Update and possibly print the progressbar.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    706\u001b[0m                 \u001b[0;31m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    707\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[call-arg]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 708\u001b[0;31m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_next_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    709\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_num_yielded\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    710\u001b[0m             if (\n",
      "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m_next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    762\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_next_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    763\u001b[0m         \u001b[0mindex\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_next_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# may raise StopIteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 764\u001b[0;31m         \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataset_fetcher\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfetch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# may raise StopIteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    765\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_pin_memory\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    766\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_utils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_pin_memory_device\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/utils/data/_utils/fetch.py\u001b[0m in \u001b[0;36mfetch\u001b[0;34m(self, possibly_batched_index)\u001b[0m\n\u001b[1;32m     50\u001b[0m                 \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__getitems__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     51\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 52\u001b[0;31m                 \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0midx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     53\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     54\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/utils/data/_utils/fetch.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     50\u001b[0m                 \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__getitems__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     51\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 52\u001b[0;31m                 \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0midx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     53\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     54\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/tmp/ipykernel_35/2763934543.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, idx)\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m         \u001b[0;31m# load image\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 15\u001b[0;31m         \u001b[0mimage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcv2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     16\u001b[0m         \u001b[0mimage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcv2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcvtColor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimage\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcv2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mCOLOR_BGR2RGB\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "def ctc_decode(preds):\n",
    "    results = []\n",
    "    prev = -1\n",
    "    for p in preds:\n",
    "        if p != prev and p != 0:  # skip duplicates and blank token\n",
    "            results.append(p)\n",
    "        prev = p\n",
    "    return decode_plate_model(results)\n",
    "\n",
    "\n",
    "# training loop\n",
    "for epoch in range(300):\n",
    "    model.train()\n",
    "    total_loss = 0\n",
    "\n",
    "    for imgs, texts in loader:\n",
    "        imgs = imgs.to(device)\n",
    "\n",
    "        # encoding targets\n",
    "        encoded_targets = [torch.tensor(encode_plate(t), dtype=torch.long) for t in texts]\n",
    "        target_lengths = torch.tensor([len(seq) for seq in encoded_targets], dtype=torch.long)\n",
    "        targets = torch.cat(encoded_targets)\n",
    "        \n",
    "        # forward\n",
    "        logits = model(imgs)\n",
    "        log_probs = logits.log_softmax(2).permute(1, 0, 2)\n",
    "\n",
    "         # all have same input length (108 from encoder block)\n",
    "        input_lengths = torch.full(\n",
    "            size=(logits.size(0),), \n",
    "            fill_value=logits.size(1),  # 18\n",
    "            dtype=torch.long,\n",
    "            device=logits.device\n",
    "        )\n",
    "\n",
    "        # loss = simple_ctc_loss(log_probs,targets,input_lengths,target_lengths,blank=0)\n",
    "        # uses CTC from torch\n",
    "        loss = ctc_loss(\n",
    "            log_probs,\n",
    "            targets,\n",
    "            input_lengths,\n",
    "            target_lengths\n",
    "        )\n",
    "\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()  \n",
    "        torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=1.0)\n",
    "        optimizer.step()\n",
    "\n",
    "        total_loss += loss.item()\n",
    "\n",
    "    scheduler.step()\n",
    "\n",
    "    print(f\"Epoch [{epoch}/300] - Loss: {total_loss / len(loader):.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2025-06-13T18:31:40.535178Z",
     "iopub.status.idle": "2025-06-13T18:31:40.535414Z",
     "shell.execute_reply": "2025-06-13T18:31:40.535309Z",
     "shell.execute_reply.started": "2025-06-13T18:31:40.535299Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# saves the weights\n",
    "torch.save(model.state_dict(), \"pdlpr_model_weights.pth\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2025-06-13T18:31:40.536442Z",
     "iopub.status.idle": "2025-06-13T18:31:40.536764Z",
     "shell.execute_reply": "2025-06-13T18:31:40.536654Z",
     "shell.execute_reply.started": "2025-06-13T18:31:40.536637Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# overfitting function in order to check if there is any structural problem\n",
    "\n",
    "def overfit_single_plate(model, loader, encode_plate, ctc_decode, device):\n",
    "    model.to(device)\n",
    "    model.train()\n",
    "\n",
    "    # testing reducing model complexity\n",
    "    if hasattr(model.decoder, 'decoder_layers'):\n",
    "        model.decoder.decoder_layers = nn.ModuleList([model.decoder.decoder_layers[0]])\n",
    "\n",
    "    # disable dropout (testing)\n",
    "    if hasattr(model.encoder, 'dropout'):\n",
    "        model.encoder.dropout.p = 0.0\n",
    "    if hasattr(model.decoder, 'dropout'):\n",
    "        model.decoder.dropout.p = 0.0\n",
    "\n",
    "    # only one sample\n",
    "    img, text = next(iter(loader))\n",
    "    img = img[0:1].to(device)\n",
    "    text = text[0]\n",
    "    print(f\"\\n True plate: {text}\")\n",
    "\n",
    "    # encode target\n",
    "    target = torch.tensor(encode_plate(text), dtype=torch.long).to(device)\n",
    "    targets = target\n",
    "    target_lengths = torch.tensor([len(target)], dtype=torch.long).to(device)\n",
    "\n",
    "    # loss and optimizer\n",
    "    ctc_loss = nn.CTCLoss(blank=0, zero_infinity=True)\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=1e-3)\n",
    "\n",
    "    # overfitting loop\n",
    "    for epoch in range(1, 201):\n",
    "        model.train()\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        logits = model(img)\n",
    "        log_probs = logits.log_softmax(2).permute(1, 0, 2)\n",
    "        input_lengths = torch.full((1,), logits.size(1), dtype=torch.long).to(device)\n",
    "\n",
    "        loss = ctc_loss(log_probs, targets, input_lengths, target_lengths)\n",
    "        loss.backward()\n",
    "        clip_grad_norm_(model.parameters(), 1.0)\n",
    "        optimizer.step()\n",
    "\n",
    "        with torch.no_grad():\n",
    "            pred_tokens = log_probs.detach().argmax(dim=2).permute(1, 0)\n",
    "            decoded = ctc_decode(pred_tokens[0].tolist())\n",
    "\n",
    "        if decoded == text:\n",
    "            print(\"overfit successful\")\n",
    "            break\n",
    "\n",
    "overfit_single_plate(model, loader, encode_plate, ctc_decode, device)"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "nvidiaTeslaT4",
   "dataSources": [
    {
     "datasetId": 7657021,
     "sourceId": 12157766,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 31041,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
